
Top 50 results (sorted by loss):
Rank 1, loss = 0.019551318138837814
    weight_init_kwargs: {'gain': 1.0}
    lr: 0.001
    act_fn: Sin(freq=1.0)
    width: 128
    depth: 4
Rank 2, loss = 0.021798288449645042
    weight_init_kwargs: {'gain': 1.5}
    lr: 0.0001
    act_fn: Tanh()
    width: 256
    depth: 10
Rank 3, loss = 0.02377980947494507
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.01
    act_fn: Sin(freq=1.0)
    width: 128
    depth: 4
Rank 4, loss = 0.024190226569771767
    weight_init_kwargs: {'gain': 1.5}
    lr: 0.001
    act_fn: SiLU()
    width: 128
    depth: 10
Rank 5, loss = 0.029932808130979538
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.01
    act_fn: SiLU()
    width: 32
    depth: 8
Rank 6, loss = 0.05985461175441742
    weight_init_kwargs: {'gain': 1.5}
    lr: 0.001
    act_fn: SiLU()
    width: 32
    depth: 4
Rank 7, loss = 0.06697256863117218
    weight_init_kwargs: {'gain': 1.0}
    lr: 0.01
    act_fn: PolyReLU(n=3)
    width: 128
    depth: 4
Rank 8, loss = 0.06731417775154114
    weight_init_kwargs: {'gain': 1.5}
    lr: 0.001
    act_fn: SiLU()
    width: 256
    depth: 4
Rank 9, loss = 0.07869631797075272
    weight_init_kwargs: {'gain': 1.5}
    lr: 1e-05
    act_fn: Tanh()
    width: 256
    depth: 8
Rank 10, loss = 0.19238151609897614
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.01
    act_fn: Tanh()
    width: 32
    depth: 10
Rank 11, loss = 0.28429123759269714
    weight_init_kwargs: {'gain': 1.5}
    lr: 0.01
    act_fn: Tanh()
    width: 32
    depth: 8
Rank 12, loss = 0.32891160249710083
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.001
    act_fn: Sin(freq=1.0)
    width: 64
    depth: 8
Rank 13, loss = 0.4319469928741455
    weight_init_kwargs: {'gain': 1.5}
    lr: 0.01
    act_fn: Tanh()
    width: 32
    depth: 10
Rank 14, loss = 0.831748366355896
    weight_init_kwargs: {'gain': 1.5}
    lr: 0.0001
    act_fn: Tanh()
    width: 64
    depth: 4
Rank 15, loss = 0.8559947609901428
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.01
    act_fn: PolyReLU(n=2)
    width: 128
    depth: 4
Rank 16, loss = 0.9309865832328796
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.001
    act_fn: Tanh()
    width: 32
    depth: 8
Rank 17, loss = 1.4032025337219238
    weight_init_kwargs: {'gain': 1.5}
    lr: 0.01
    act_fn: PolyReLU(n=2)
    width: 128
    depth: 8
Rank 18, loss = 1.9923001527786255
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.001
    act_fn: SiLU()
    width: 256
    depth: 10
Rank 19, loss = 2.2324740886688232
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.001
    act_fn: Sin(freq=1.0)
    width: 32
    depth: 8
Rank 20, loss = 2.4259941577911377
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.0001
    act_fn: SiLU()
    width: 32
    depth: 10
Rank 21, loss = 3.980135679244995
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.01
    act_fn: PolyReLU(n=4)
    width: 256
    depth: 2
Rank 22, loss = 8.523589134216309
    weight_init_kwargs: {'gain': 1.0}
    lr: 0.001
    act_fn: Sin(freq=1.0)
    width: 256
    depth: 2
Rank 23, loss = 8.547576904296875
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.01
    act_fn: Tanh()
    width: 256
    depth: 2
Rank 24, loss = 8.668379783630371
    weight_init_kwargs: {'gain': 1.0}
    lr: 0.001
    act_fn: Sin(freq=1.0)
    width: 32
    depth: 2
Rank 25, loss = 15.778399467468262
    weight_init_kwargs: {'gain': 1.0}
    lr: 1e-05
    act_fn: Sin(freq=1.0)
    width: 32
    depth: 8
Rank 26, loss = 16.832597732543945
    weight_init_kwargs: {'gain': 0.5}
    lr: 1e-05
    act_fn: SiLU()
    width: 128
    depth: 10
Rank 27, loss = 23.19768714904785
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.0001
    act_fn: Sin(freq=1.0)
    width: 32
    depth: 10
Rank 28, loss = 31.275644302368164
    weight_init_kwargs: {'gain': 1.0}
    lr: 1e-05
    act_fn: Sin(freq=1.0)
    width: 128
    depth: 4
Rank 29, loss = 44.905357360839844
    weight_init_kwargs: {'gain': 1.5}
    lr: 1e-05
    act_fn: SiLU()
    width: 256
    depth: 4
Rank 30, loss = 44.93568420410156
    weight_init_kwargs: {'gain': 1.0}
    lr: 0.0001
    act_fn: SiLU()
    width: 256
    depth: 2
Rank 31, loss = 47.64191436767578
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.01
    act_fn: PolyReLU(n=2)
    width: 32
    depth: 2
Rank 32, loss = 59.562705993652344
    weight_init_kwargs: {'gain': 0.5}
    lr: 1e-05
    act_fn: Sin(freq=1.0)
    width: 128
    depth: 8
Rank 33, loss = 69.89234161376953
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.0001
    act_fn: Tanh()
    width: 32
    depth: 2
Rank 34, loss = 72.98603820800781
    weight_init_kwargs: {'gain': 1.5}
    lr: 0.01
    act_fn: Sin(freq=1.0)
    width: 128
    depth: 10
Rank 35, loss = 89.64395904541016
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.0001
    act_fn: PolyReLU(n=4)
    width: 32
    depth: 4
Rank 36, loss = 90.0958251953125
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.01
    act_fn: PolyReLU(n=3)
    width: 32
    depth: 10
Rank 37, loss = 91.10590362548828
    weight_init_kwargs: {'gain': 0.5}
    lr: 1e-05
    act_fn: PolyReLU(n=3)
    width: 256
    depth: 8
Rank 38, loss = 91.83065032958984
    weight_init_kwargs: {'gain': 0.5}
    lr: 1e-05
    act_fn: SiLU()
    width: 128
    depth: 2
Rank 39, loss = 91.95061492919922
    weight_init_kwargs: {'gain': 0.5}
    lr: 1e-05
    act_fn: PolyReLU(n=2)
    width: 128
    depth: 4
Rank 40, loss = 92.09403991699219
    weight_init_kwargs: {'gain': 0.5}
    lr: 0.01
    act_fn: PolyReLU(n=2)
    width: 64
    depth: 8
Rank 41, loss = 92.28583526611328
    weight_init_kwargs: {'gain': 1.0}
    lr: 0.001
    act_fn: PolyReLU(n=4)
    width: 64
    depth: 8
Rank 42, loss = 93.35266876220703
    weight_init_kwargs: {'gain': 1.0}
    lr: 0.01
    act_fn: PolyReLU(n=4)
    width: 32
    depth: 8
Rank 43, loss = 93.40840911865234
    weight_init_kwargs: {'gain': 1.0}
    lr: 0.001
    act_fn: PolyReLU(n=3)
    width: 256
    depth: 10
Rank 44, loss = 93.43119049072266
    weight_init_kwargs: {'gain': 1.5}
    lr: 1e-05
    act_fn: PolyReLU(n=2)
    width: 32
    depth: 10
Rank 45, loss = 93.75127410888672
    weight_init_kwargs: {'gain': 1.5}
    lr: 1e-05
    act_fn: PolyReLU(n=2)
    width: 256
    depth: 10
Rank 46, loss = 93.78337097167969
    weight_init_kwargs: {'gain': 1.0}
    lr: 1e-05
    act_fn: PolyReLU(n=3)
    width: 32
    depth: 2
Rank 47, loss = 94.0560302734375
    weight_init_kwargs: {'gain': 0.5}
    lr: 1e-05
    act_fn: PolyReLU(n=3)
    width: 64
    depth: 8
Rank 48, loss = 94.46652221679688
    weight_init_kwargs: {'gain': 1.5}
    lr: 0.0001
    act_fn: PolyReLU(n=4)
    width: 64
    depth: 8
Rank 49, loss = 94.52371215820312
    weight_init_kwargs: {'gain': 1.0}
    lr: 1e-05
    act_fn: PolyReLU(n=2)
    width: 256
    depth: 2
Rank 50, loss = 136.80889892578125
    weight_init_kwargs: {'gain': 1.5}
    lr: 0.01
    act_fn: Sin(freq=1.0)
    width: 256
    depth: 10

--------------------------------------------------
